---
title: 'Examples'
description: 'Examples for common scenarios'
---

<CardGroup cols={2}>
  <Card
    title="RAG"
    href="https://github.com/empirical-run/empirical/tree/main/examples/rag"
  >
    Tests a Retrieval-augmented Generation application built with LlamaIndex, scored on
    metrics from RAGAS.
  </Card>
  <Card
    title="HumanEval"
    href="https://github.com/empirical-run/empirical/tree/main/examples/humaneval"
  >
    Uses a custom Python scoring function to run the HumanEval benchmark, which is
    a popular dataset for code generation tasks.
  </Card>
  <Card
    title="Spider"
    href="https://github.com/empirical-run/empirical/tree/main/examples/spider"
  >
    Runs the Spider dataset to demo text-to-SQL and relevant scorer functions.
  </Card>
  <Card
    title="Chat bot"
    href="https://github.com/empirical-run/empirical/tree/main/examples/chatbot"
  >
    Uses an LLM to grade the output responses and ensure that they do not
    contain "as a AI language model" in them.
  </Card>
  <Card
    title="Basic"
    href="https://github.com/empirical-run/empirical/tree/main/examples/basic"
  >
    Uses an entity extraction use-case to check for valid JSON outputs.
  </Card>
</CardGroup>
