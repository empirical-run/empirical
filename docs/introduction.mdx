---
title: Introduction
description: 'Welcome to empirical.run'
---

Empirical is the fastest way to test different LLMs, prompts and other model configurations, across all the scenarios
that matter for your application.

[Try it out!](./quickstart)

## With Empirical, you can

- Run your test datasets locally against off-the-shelf models
- Test your own custom models and RAG applications (see [how-to](./models/custom))
- Reports to view, compare, analyze outputs on a web UI
- Score your outputs with [scoring functions](./scoring/basics)
- Run [tests on CI/CD](./running-in-ci)


## Walk through

Watch a 6 mins demo video showing how Empirical can run the [HumanEval benchmark](https://github.com/empirical-run/empirical/tree/main/examples/humaneval).

<div style={{position: "relative", paddingBottom: "56.25%", height: 0}}>
  <iframe src="https://www.loom.com/embed/5992fdf0edc443e282f44936e6c32672?sid=ac55c278-e1d9-4735-8840-214ed29d35f0"
    frameborder="0"
    webkitallowfullscreen
    mozallowfullscreen
    allowfullscreen
    style={{position: 'absolute', top: 0, left: 0, width: '100%', height: '100%'}}>
  </iframe>
</div>

## Open source

Empirical is open source on [GitHub](https://github.com/empirical-run/empirical). Star the repo, file issues or pull requests
to contribute to the project.
